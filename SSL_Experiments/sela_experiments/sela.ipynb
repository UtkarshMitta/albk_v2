{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from astra.torch.models import ResNetClassifier,ResNet18_Weights\n",
    "# from astra.torch.data import load_cifar_10\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from glob import glob\n",
    "from os.path import expanduser, join, basename, dirname\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from itertools import product\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from astra.torch.models import ResNetClassifier,ResNet18_Weights\n",
    "from astra.torch.utils import train_fn\n",
    "\n",
    "import torchvision.models as models\n",
    "from astra.torch.metrics import accuracy_score, f1_score, precision_score, recall_score,classification_report\n",
    "import torch\n",
    "import torchvision\n",
    "from PIL import Image\n",
    "import torch.nn as nn\n",
    "import os\n",
    "from copy import deepcopy\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2487638/1349503276.py:9: UserWarning: TORCH_HOME not set, setting it to /home/rishabh.mondal/.cache/torch\n",
      "  warnings.warn(f\"TORCH_HOME not set, setting it to {os.environ['TORCH_HOME']}\")\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import warnings\n",
    "import torchvision.datasets\n",
    "from PIL import Image  # Import the Image module from the PIL library\n",
    "\n",
    "def prerequisite(f):\n",
    "    if \"TORCH_HOME\" not in os.environ:\n",
    "        os.environ[\"TORCH_HOME\"] = os.path.expanduser(\"~/.cache/torch\")\n",
    "        warnings.warn(f\"TORCH_HOME not set, setting it to {os.environ['TORCH_HOME']}\")\n",
    "    return f\n",
    "\n",
    "prerequisite(None)\n",
    "class CIFAR10Instance(torchvision.datasets.CIFAR10):\n",
    "    \"\"\"CIFAR10Instance Dataset.\"\"\"\n",
    "    def __init__(self, root=f\"{os.environ['TORCH_HOME']}/data\", train=True, transform=None, target_transform=None, download=True):\n",
    "        super(CIFAR10Instance, self).__init__(root=root,\n",
    "                                              train=train,\n",
    "                                              transform=transform,\n",
    "                                              target_transform=target_transform)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # Your implementation of __getitem__ method\n",
    "        image, target = self.data[index], self.targets[index]\n",
    "\n",
    "        # Convert numpy array to PIL Image\n",
    "        image = Image.fromarray(image)\n",
    "\n",
    "        if self.transform is not None:\n",
    "            img = self.transform(image)\n",
    "\n",
    "        if self.target_transform is not None:\n",
    "            target = self.target_transform(target)\n",
    "\n",
    "        return img, target, index  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.transforms as tfs\n",
    "transform_train = tfs.Compose([\n",
    "    tfs.Resize(256),\n",
    "    tfs.RandomResizedCrop(size=224, scale=(0.2, 1.)),\n",
    "    tfs.ColorJitter(0.4, 0.4, 0.4, 0.4),\n",
    "    tfs.RandomGrayscale(p=0.2),\n",
    "    tfs.RandomHorizontalFlip(),\n",
    "    tfs.ToTensor(),\n",
    "    tfs.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset=CIFAR10Instance(root=f\"{os.environ['TORCH_HOME']}/data\", train=True, download=True, transform=transform_train)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=128, shuffle=True, num_workers=8)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch.nn as nn\n",
    "\n",
    "__all__ = [ 'AlexNet', 'alexnet']\n",
    " \n",
    "# (number of filters, kernel size, stride, pad)\n",
    "CFG = {\n",
    "    'big': [(96, 11, 4, 2), 'M', (256, 5, 1, 2), 'M', (384, 3, 1, 1), (384, 3, 1, 1), (256, 3, 1, 1), 'M'],\n",
    "    'small': [(64, 11, 4, 2), 'M', (192, 5, 1, 2), 'M', (384, 3, 1, 1), (256, 3, 1, 1), (256, 3, 1, 1), 'M']\n",
    "}\n",
    "\n",
    "class AlexNet(nn.Module):\n",
    "    def __init__(self, features, num_classes, init=True):\n",
    "        super(AlexNet, self).__init__()\n",
    "        self.features = features\n",
    "        self.classifier = nn.Sequential(nn.Dropout(0.5),\n",
    "                            nn.Linear(256 * 6 * 6, 4096),\n",
    "                            nn.ReLU(inplace=True),\n",
    "                            nn.Dropout(0.5),\n",
    "                            nn.Linear(4096, 4096),\n",
    "                            nn.ReLU(inplace=True))\n",
    "        self.headcount = len(num_classes)\n",
    "        self.return_features = False\n",
    "        if len(num_classes) == 1:\n",
    "            self.top_layer = nn.Linear(4096, num_classes[0])\n",
    "        else:\n",
    "            for a,i in enumerate(num_classes):\n",
    "                setattr(self, \"top_layer%d\" % a, nn.Linear(4096, i))\n",
    "            self.top_layer = None  # this way headcount can act as switch.\n",
    "        if init:\n",
    "            self._initialize_weights()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = x.view(x.size(0), 256 * 6 * 6)\n",
    "        x = self.classifier(x)\n",
    "        if self.return_features: # switch only used for CIFAR-experiments\n",
    "            return x\n",
    "        if self.headcount == 1:\n",
    "            if self.top_layer: # this way headcount can act as switch.\n",
    "                x = self.top_layer(x)\n",
    "            return x\n",
    "        else:\n",
    "            outp = []\n",
    "            for i in range(self.headcount):\n",
    "                outp.append(getattr(self, \"top_layer%d\" % i)(x))\n",
    "            return outp\n",
    "\n",
    "    def _initialize_weights(self):\n",
    "        for y, m in enumerate(self.modules()):\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
    "                for i in range(m.out_channels):\n",
    "                    m.weight.data[i].normal_(0, math.sqrt(2. / n))\n",
    "                if m.bias is not None:\n",
    "                    m.bias.data.zero_()\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                m.weight.data.fill_(1)\n",
    "                m.bias.data.zero_()\n",
    "            elif isinstance(m, nn.Linear):\n",
    "                m.weight.data.normal_(0, 0.01)\n",
    "                m.bias.data.zero_()\n",
    "\n",
    "\n",
    "def make_layers_features(cfg, input_dim, bn):\n",
    "    layers = []\n",
    "    in_channels = input_dim\n",
    "    for v in cfg:\n",
    "        if v == 'M':\n",
    "            layers += [nn.MaxPool2d(kernel_size=3, stride=2)]\n",
    "        else:\n",
    "            conv2d = nn.Conv2d(in_channels, v[0], kernel_size=v[1], stride=v[2], padding=v[3])#,bias=False)\n",
    "            if bn:\n",
    "                layers += [conv2d, nn.BatchNorm2d(v[0]), nn.ReLU(inplace=True)]\n",
    "            else:\n",
    "                layers += [conv2d, nn.ReLU(inplace=True)]\n",
    "            in_channels = v[0]\n",
    "    return nn.Sequential(*layers)\n",
    "\n",
    "\n",
    "def alexnet(bn=True, num_classes=[1000], init=True, size='big'):\n",
    "    dim = 3\n",
    "    model = AlexNet(make_layers_features(CFG[size], dim, bn=bn), num_classes, init)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset = load_cifar_10()\n",
    "# n_train=10\n",
    "# n_test=20000\n",
    "# y=dataset.targets\n",
    "# x=dataset.data\n",
    "# classes=dataset.classes\n",
    "# class_1_idx=classes.index('frog')\n",
    "# class_1_mask=y==class_1_idx\n",
    "# y=class_1_mask.byte()\n",
    "# dataset = load_cifar_10()\n",
    "# idx=torch.randperm(len(y))\n",
    "# train_data=x[idx[:n_train]]\n",
    "# train_targets=y[idx[:n_train]]\n",
    "# test_data=x[idx[-n_test:]]\n",
    "# test_targets=y[idx[-n_test:]]\n",
    "# pool_data=x[idx[n_train:-n_test]]\n",
    "# pool_targets=y[idx[n_train:-n_test]]\n",
    "# # train_dataset=TensorDataset(train_data,train_targets)\n",
    "# # test_dataset=TensorDataset(test_data,test_targets)\n",
    "# # pool_dataset=TensorDataset(pool_data,pool_targets)\n",
    "# # train_loader=DataLoader(train_dataset,batch_size=254,shuffle=True)\n",
    "# # test_loader=DataLoader(test_dataset,batch_size=254,shuffle=False)\n",
    "# # pool_loader=DataLoader(pool_dataset,batch_size=254,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torchvision.transforms as transforms\n",
    "\n",
    "# aug = transforms.Compose([\n",
    "#     transforms.Resize(256),\n",
    "#     transforms.RandomResizedCrop(224,scale=(0.2,1.0)),\n",
    "#     transforms.RandomGrayscale(p=0.2),\n",
    "#     transforms.ColorJitter(0.4, 0.4, 0.4, 0.4),\n",
    "#     transforms.RandomHorizontalFlip(),\n",
    "#     transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "#                          std=[0.229, 0.224, 0.225])\n",
    "# ])\n",
    "# augmented_train_data=aug(train_data)\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# # Assuming augmented_train_data is a list of images with shape (3, 32, 32)\n",
    "# fig, axes = plt.subplots(1, 10, figsize=(15, 3))\n",
    "\n",
    "# for i in range(10):\n",
    "#     # Transpose the dimensions to (32, 32, 3) for RGB image\n",
    "#     image_to_display = augmented_train_data[i].permute(1, 2, 0)\n",
    "#     image_to_display = (image_to_display - image_to_display.min()) / (image_to_display.max() - image_to_display.min())\n",
    "\n",
    "#     axes[i].imshow(image_to_display)\n",
    "#     axes[i].axis('off')\n",
    "\n",
    "# plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from torch.utils.data import DataLoader\n",
    "\n",
    "# # Assuming augmented_train_data and train_targets are already defined\n",
    "# train_dataset = TensorDataset(augmented_train_data, train_targets)\n",
    "# train_loader = DataLoader(train_dataset, batch_size=256, shuffle=True,num_workers=8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.models as models\n",
    "import torch.nn as nn\n",
    "\n",
    "# train_model = ResNetClassifier(\n",
    "#     models.resnet18,None, n_classes=5, activation=nn.GELU(), dropout=0.1\n",
    "# ).to(\"cuda\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial Random Label Assignment\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_model.eval()\n",
    "# with torch.no_grad():\n",
    "#     y_pred = train_model(augmented_train_data.to(\"cuda\"))\n",
    "#     print(y_pred.shape)\n",
    "\n",
    "# print(y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Self Labelling with Optimal Transport\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Constraint:\n",
    "The unlabeled images should be divided equally into the K clusters. This is referred to as the equipartition condition in the paper.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def genarate_optimal_matrix(N,K):\n",
    "#     images_per_cluster=N//K\n",
    "#     print(images_per_cluster)\n",
    "#     matrix=np.zeros((N,K),dtype=int)\n",
    "#     for j in range(K):\n",
    "#         start_index=j*images_per_cluster\n",
    "#         print(start_index)\n",
    "#         end_index=(j+1)*images_per_cluster\n",
    "#         matrix[start_index:end_index,j]=1\n",
    "#     return matrix\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# N = len(augmented_train_data)  # Number of unlabeled images\n",
    "# K = 5  \n",
    "# genarate_optimal_matrix(N,K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=AlexNet(make_layers_features(CFG['big'], 3, bn=True), [5], init=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cost Matrix:\n",
    "The cost of allocating each image to a cluster is given by the model performance when trained using these clusters as the labels. Intuitively, this means the mistake model is making when we assign an unlabeled image to some cluster. If it is high, then that means our current label assignment is not ideal and so we should change it in the optimization step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# import numpy as np\n",
    "\n",
    "# # Assuming train_model is your PyTorch model\n",
    "# # Assuming unlabeled_images is your batch of unlabeled images\n",
    "# # Assuming optimal_assignment_matrix is the optimal assignment matrix generated previously\n",
    "# import torch.nn.functional as F\n",
    "# # Set the model to evaluation mode\n",
    "# train_model.eval()\n",
    "\n",
    "# # Move the unlabeled images to the appropriate device (GPU or CPU)\n",
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# unlabeled_images = augmented_train_data.to(device)\n",
    "# optimal_assignment_matrix = genarate_optimal_matrix(N,K)\n",
    "# # Calculate the model's loss for each image-cluster assignment\n",
    "# cost_matrix = np.zeros((len(unlabeled_images), optimal_assignment_matrix.shape[1]))\n",
    "\n",
    "# with torch.no_grad():\n",
    "#     for i in range(len(unlabeled_images)):\n",
    "#         image = unlabeled_images[i].unsqueeze(0)  # Add batch dimension\n",
    "#         for j in range(optimal_assignment_matrix.shape[1]):\n",
    "#             # Extract the cluster assignment for the current image\n",
    "#             cluster_assignment = optimal_assignment_matrix[i, j]\n",
    "\n",
    "#             # Convert cluster_assignment to a PyTorch tensor (1D tensor)\n",
    "#             cluster_assignment_tensor = torch.tensor([cluster_assignment], dtype=torch.long, device=device)\n",
    "\n",
    "#             # Forward pass to get model predictions\n",
    "#             predictions = train_model(image)\n",
    "\n",
    "#             # Calculate CrossEntropyLoss based on the cluster assignment\n",
    "#             loss = F.cross_entropy(predictions, cluster_assignment_tensor)\n",
    "            \n",
    "#             # Store the loss in the cost matrix\n",
    "#             cost_matrix[i, j] = loss.item()\n",
    "\n",
    "# # Display the cost matrix\n",
    "# print(\"Cost Matrix:\")\n",
    "# print(cost_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=model.to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_l_sk(PS):\n",
    "    N,K=PS.shape\n",
    "    print(PS.shape)\n",
    "    # print(N,K)\n",
    "    PS=PS.T # now it is K,N\n",
    "    # print(PS.shape)\n",
    "    # print(PS)\n",
    "    r=np.ones((K,1))/K\n",
    "    # print(r)\n",
    "    c=np.ones((N,1))/N\n",
    "    # print(c)\n",
    "    # print(PS)\n",
    "    PS**=10\n",
    "    PS*= np.squeeze(c)\n",
    "    # print(PS)\n",
    "    PS=PS.T\n",
    "    # print(PS)\n",
    "    PS*= np.squeeze(r)\n",
    "    # print(PS)\n",
    "    PS=PS.T\n",
    "    # print(PS)\n",
    "    argmax=np.argmax(PS,axis=0)\n",
    "    print(argmax)\n",
    "    newLabels=torch.LongTensor(argmax)\n",
    "    print(newLabels)\n",
    "    PS=PS.T\n",
    "    # print(PS)\n",
    "    PS/= np.squeeze(r)\n",
    "    # print(PS)\n",
    "    PS=PS.T\n",
    "    # print(PS)\n",
    "    PS/= np.squeeze(c)\n",
    "    # print(PS)\n",
    "    sol=PS[argmax,np.arange(N)]\n",
    "    # print(sol)\n",
    "    np.log(sol,sol)\n",
    "    print(\"sol\",sol)\n",
    "    print(\"nansum\",np.nansum(sol))\n",
    "    cost=-(1.0/10)*np.nansum(sol)/N\n",
    "    print(\"cost\",cost)\n",
    "    return cost,newLabels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.special import logsumexp\n",
    "def py_softmax(x, axis=None):\n",
    "    \"\"\"stable softmax\"\"\"\n",
    "    return np.exp(x - logsumexp(x, axis=axis, keepdims=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def opt_sk(hc,model, selflabels_in, epoch,knn_dim,ncl):\n",
    "    if hc == 1:\n",
    "        PS = np.zeros((len(trainloader.dataset), ncl))\n",
    "    else:\n",
    "        PS_pre = np.zeros((len(trainloader.dataset), knn_dim))\n",
    "    for batch_idx, (data, _, _selected) in enumerate(trainloader):\n",
    "        data = data.cuda()\n",
    "        if hc == 1:\n",
    "            p = nn.functional.softmax(model(data), 1)\n",
    "            PS[_selected, :] = p.detach().cpu().numpy()\n",
    "        else:\n",
    "            p = model(data)\n",
    "            PS_pre[_selected, :] = p.detach().cpu().numpy()\n",
    "    if hc == 1:\n",
    "        cost, selflabels = optimize_l_sk(PS)\n",
    "        _costs = [cost]\n",
    "    else:\n",
    "        _nmis = np.zeros(hc)\n",
    "        _costs = np.zeros(hc)\n",
    "        nh = epoch % hc  # np.random.randint(args.hc)\n",
    "        print(\"computing head %s \" % nh, end=\"\\r\", flush=True)\n",
    "        tl = getattr(model, \"top_layer%d\" % nh)\n",
    "        # do the forward pass:\n",
    "        PS = (PS_pre @ tl.weight.cpu().numpy().T\n",
    "                   + tl.bias.cpu().numpy())\n",
    "        PS = py_softmax(PS, 1)\n",
    "        c, selflabels_ = optimize_l_sk(PS)\n",
    "        _costs[nh] = c\n",
    "        selflabels_in[nh] = selflabels_\n",
    "        selflabels = selflabels_in\n",
    "    return selflabels\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;31mSignature:\u001b[0m \u001b[0mopt_sk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mselflabels_in\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mknn_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mncl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mDocstring:\u001b[0m <no docstring>\n",
      "\u001b[0;31mFile:\u001b[0m      /tmp/ipykernel_2487638/940078020.py\n",
      "\u001b[0;31mType:\u001b[0m      function"
     ]
    }
   ],
   "source": [
    "opt_sk?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing head 10 \r"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'AlexNet' object has no attribute 'top_layer10'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 8\u001b[0m\n\u001b[1;32m      6\u001b[0m knn_dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m\n\u001b[1;32m      7\u001b[0m ncl\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m\n\u001b[0;32m----> 8\u001b[0m \u001b[43mopt_sk\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m128\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[18], line 22\u001b[0m, in \u001b[0;36mopt_sk\u001b[0;34m(hc, model, selflabels_in, epoch, knn_dim, ncl)\u001b[0m\n\u001b[1;32m     20\u001b[0m nh \u001b[38;5;241m=\u001b[39m epoch \u001b[38;5;241m%\u001b[39m hc  \u001b[38;5;66;03m# np.random.randint(args.hc)\u001b[39;00m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcomputing head \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m nh, end\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, flush\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m---> 22\u001b[0m tl \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(model, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtop_layer\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m nh)\n\u001b[1;32m     23\u001b[0m \u001b[38;5;66;03m# do the forward pass:\u001b[39;00m\n\u001b[1;32m     24\u001b[0m PS \u001b[38;5;241m=\u001b[39m (PS_pre \u001b[38;5;241m@\u001b[39m tl\u001b[38;5;241m.\u001b[39mweight\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy()\u001b[38;5;241m.\u001b[39mT\n\u001b[1;32m     25\u001b[0m            \u001b[38;5;241m+\u001b[39m tl\u001b[38;5;241m.\u001b[39mbias\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy())\n",
      "File \u001b[0;32m~/miniconda3/envs/torch_space/lib/python3.11/site-packages/torch/nn/modules/module.py:1695\u001b[0m, in \u001b[0;36mModule.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1693\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m modules:\n\u001b[1;32m   1694\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m modules[name]\n\u001b[0;32m-> 1695\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m object has no attribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'AlexNet' object has no attribute 'top_layer10'"
     ]
    }
   ],
   "source": [
    "hc=20\n",
    "model=alexnet(bn=True, num_classes=[5], init=True, size='big')\n",
    "model=model.to('cuda')\n",
    "selflabels_in = [None] * hc\n",
    "epoch=1\n",
    "knn_dim=5\n",
    "ncl=5\n",
    "opt_sk(20,model,1,50,5,128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[4, 0, 4,  ..., 1, 1, 4],\n",
      "        [4, 2, 2,  ..., 4, 1, 3],\n",
      "        [0, 0, 3,  ..., 0, 2, 1],\n",
      "        ...,\n",
      "        [3, 1, 2,  ..., 2, 0, 0],\n",
      "        [0, 1, 1,  ..., 2, 3, 1],\n",
      "        [3, 2, 2,  ..., 3, 4, 2]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from torchvision.models import alexnet\n",
    "\n",
    "numc = hc * ncl\n",
    "# model = alexnet(bn=True, num_classes=[numc], init=True, size='big')\n",
    "# model = model.to('cuda')\n",
    "N = len(trainloader.dataset)\n",
    "\n",
    "# Init selflabels randomly\n",
    "if hc == 1:\n",
    "    selflabels = torch.randint(0, ncl, (N,), dtype=torch.long).cuda()\n",
    "else:\n",
    "    selflabels = torch.zeros((hc, N), dtype=torch.long).cuda()\n",
    "    for nh in range(hc):\n",
    "        indices = torch.arange(N) % ncl\n",
    "        shuffled_indices = torch.randperm(N).to('cuda')\n",
    "        selflabels[nh] = indices.to('cuda')[shuffled_indices]\n",
    "\n",
    "# Convert selflabels to long tensor\n",
    "selflabels = selflabels.long().cuda()\n",
    "print(selflabels)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# # Assuming trainloader is your data loader for the images\n",
    "# # Assuming selflabels is the assigned selflabels for the images\n",
    "# data_iter = iter(trainloader)\n",
    "# images, _, selflabels = next(data_iter)\n",
    "\n",
    "# # Assuming image is the image you want to plot\n",
    "# # Assuming selflabels is the assigned selflabels for the image\n",
    "# fig, ax = plt.subplots()\n",
    "# ax.imshow(images[0].permute(1, 2, 0).numpy())  # Convert to NumPy array for visualization\n",
    "# ax.set_title(f\"Self-label: {selflabels[0].item()}\")  # Adjust the title as needed\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch,selflabels):\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_space",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
