{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "from os.path import expanduser, join, basename, dirname\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from joblib import Parallel, delayed\n",
    "from shutil import copy\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import torch\n",
    "from tempfile import TemporaryDirectory\n",
    "\n",
    "from albk.data.utils import idx_to_locate\n",
    "use_disjoint_files = False\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from glob import glob\n",
    "from os.path import expanduser, join, basename, dirname\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "from joblib import Parallel, delayed\n",
    "from itertools import product\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from glob import glob\n",
    "from os.path import expanduser, join, basename, dirname\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from joblib import Parallel, delayed\n",
    "from itertools import product\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from astra.torch.models import EfficientNetClassifier,EfficientNet_B0_Weights\n",
    "from astra.torch.utils import train_fn\n",
    "\n",
    "import torchvision.models as models\n",
    "from astra.torch.metrics import accuracy_score, f1_score, precision_score, recall_score,classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_common_label_files(path1, path2):\n",
    "    files1 = glob(join(path1, \"*.nc\"))\n",
    "    files2 = glob(join(path2, \"*.nc\"))\n",
    "    \n",
    "    f1_base_files = [basename(f) for f in files1]\n",
    "    f2_base_files = [basename(f) for f in files2]\n",
    "    \n",
    "    common_files = set(f1_base_files).intersection(f2_base_files)\n",
    "    common_label_files = []\n",
    "    for file in common_files:\n",
    "        ds1 = xr.open_dataset(join(path1, file))\n",
    "        ds2 = xr.open_dataset(join(path2, file))\n",
    "        if np.all(ds1.label.values == ds2.label.values):\n",
    "            common_label_files.append(file)\n",
    "    \n",
    "    return list(map(lambda f: join(path1, f), common_label_files))\n",
    "\n",
    "def get_disjoint_files(path1, path2):\n",
    "    files1 = glob(join(path1, \"*.nc\"))\n",
    "    files2 = glob(join(path2, \"*.nc\"))\n",
    "    \n",
    "    f1_base_files = [basename(f) for f in files1]\n",
    "    f2_base_files = [basename(f) for f in files2]\n",
    "    \n",
    "    disjoint_files = set(f1_base_files).symmetric_difference(f2_base_files)\n",
    "    \n",
    "    f1_disjoint = [f for f in disjoint_files if f in f1_base_files]\n",
    "    f1_disjoint = list(map(lambda f: join(path1, f), f1_disjoint))\n",
    "\n",
    "    f2_disjoint = [f for f in disjoint_files if f in f2_base_files]\n",
    "    f2_disjoint = list(map(lambda f: join(path2, f), f2_disjoint))\n",
    "    \n",
    "    return f1_disjoint + f2_disjoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moderator suraj\n",
      "      Moderator files 0\n",
      "      Common label files 379\n",
      "      Disjoint files 1\n",
      "      Total files from suraj and ('shataxi', 'rishabh') 379\n",
      "      Total annotatated files 379\n",
      "Total dataset size 9475\n"
     ]
    }
   ],
   "source": [
    "base_path = expanduser(\"/home/rishabh.mondal/bangladesh_labels/bkdb/india_labels/region/power_plant\")\n",
    "paths = {\"suraj\": (\"shataxi\", \"rishabh\")}\n",
    "\n",
    "all_labeled_files = []\n",
    "for moderator, annotators in paths.items():\n",
    "    # Get moderator files\n",
    "    moderator_path = join(base_path, \"moderated\", moderator)\n",
    "    moderator_files = glob(join(moderator_path, \"*.nc\"))\n",
    "    \n",
    "    # Get annotator common label files\n",
    "    annotator1_path = join(base_path, annotators[0])\n",
    "    annotator2_path = join(base_path, annotators[1])\n",
    "    \n",
    "    common_base_files = get_common_label_files(annotator1_path, annotator2_path)\n",
    "    \n",
    "    # Get disjoint files\n",
    "    disjoint_files = get_disjoint_files(annotator1_path, annotator2_path)\n",
    "    \n",
    "    all_files = moderator_files + common_base_files\n",
    "    if use_disjoint_files:\n",
    "        all_files.extend(disjoint_files)\n",
    "    assert len(all_files) == len(set(all_files))\n",
    "    all_labeled_files.extend(all_files)\n",
    "    \n",
    "    print(\"Moderator\", moderator)\n",
    "    print(\" \"*5, \"Moderator files\", len(moderator_files))\n",
    "    print(\" \"*5, \"Common label files\", len(common_base_files))\n",
    "    print(\" \"*5, \"Disjoint files\", len(disjoint_files))\n",
    "    print(\" \"*5, f\"Total files from {moderator} and {annotators}\", len(all_files))\n",
    "    print(\" \"*5, \"Total annotatated files\", len(all_labeled_files))\n",
    "    \n",
    "print(\"Total dataset size\", len(all_labeled_files) * 25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "379\n"
     ]
    }
   ],
   "source": [
    "images_path = expanduser(\"~/bkdb/india_power_plant_data\")\n",
    "# load_path = \"/home/rishabh.mondal/Brick-Kilns-project/albk_rishabh/temporary\"\n",
    "files = all_labeled_files\n",
    "# print(files)\n",
    "print(len(files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 379/379 [00:07<00:00, 54.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<U17 torch.uint8 torch.uint8\n",
      "torch.uint8\n",
      "(9475,) torch.Size([9475, 3, 224, 224]) torch.Size([9475])\n"
     ]
    }
   ],
   "source": [
    "def get_index_and_image(file):\n",
    "    index = []\n",
    "    images = []\n",
    "    labels = []\n",
    "    base_name = basename(file)\n",
    "    # print(base_name)\n",
    "    image_path = join(images_path, base_name).replace(\".nc\", \".zarr\")\n",
    "    # print(image_path)\n",
    "    label_ds = xr.open_dataset(file)\n",
    "    # print (label_ds)\n",
    "    image_ds = xr.open_zarr(image_path, consolidated=False)\n",
    "    # image = image_ds.data.reshape(-1, 224, 224, 3)\n",
    "    for lat_lag, lon_lag in product(range(-2, 3), repeat=2):\n",
    "        index.append(base_name.replace(\".nc\", \"\")+f\"_{lat_lag}_{lon_lag}\")\n",
    "        images.append(torch.tensor(image_ds.sel(lat_lag=lat_lag, lon_lag=lon_lag)['data'].values)[np.newaxis, ...])\n",
    "        labels.append(torch.tensor((label_ds.sel(lat_lag=lat_lag, lon_lag=lon_lag)['label'].values != \"O\").astype(np.uint8)))\n",
    "        \n",
    "    return index, images, labels\n",
    "\n",
    "\n",
    "\n",
    "def get_data():\n",
    "    out = Parallel(n_jobs=32)(delayed(get_index_and_image)(file) for file in tqdm(files, total=len(files)))\n",
    "    index = np.concatenate([np.array(idx) for idx, _, _ in out])\n",
    "    images = torch.concat([torch.einsum(\"nhwc->nchw\", torch.concat(imgs)) for _, imgs, _ in out])\n",
    "    # scale\n",
    "    # images = images / 255\n",
    "    # mean normalize\n",
    "    # images = (images - images.mean(dim=(0, 2, 3), keepdim=True)) / images.std(dim=(0, 2, 3), keepdim=True)\n",
    "    \n",
    "    labels = np.concatenate([np.array(lbl) for _, _, lbl in out])\n",
    "    labels = torch.tensor(labels, dtype=torch.uint8)\n",
    "    #check the all dytpes\n",
    "    print(index.dtype, images.dtype, labels.dtype)\n",
    "    return index, images, labels\n",
    "\n",
    "index, images, labels = get_data()\n",
    "print(images.dtype)\n",
    "print(index.shape, images.shape, labels.shape)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.float32\n"
     ]
    }
   ],
   "source": [
    "# save the tensors data \n",
    "print(images.dtype)\n",
    "save_path=\"/home/rishabh.mondal/Brick-Kilns-project/albk_rishabh/tensor_data/pp.pt\"\n",
    "torch.save({\n",
    "    'index': index,\n",
    "    'images': images,\n",
    "    'labels': labels\n",
    "}, save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "image_path = \"/home/rishabh.mondal/Brick-Kilns-project/albk_rishabh/predicted_positive/baghpat/positive_image_5488.jpg\"\n",
    "\n",
    "# Read the image\n",
    "image = mpimg.imread(image_path)\n",
    "\n",
    "# Plot the image\n",
    "plt.figure(dpi=300)\n",
    "plt.imshow(image)\n",
    "plt.axis('off')\n",
    "\n",
    "# Save the image as PDF with resolution\n",
    "output_path = \"/home/rishabh.mondal/Brick-Kilns-project/albk_rishabh/positive_image_5488.pdf\"\n",
    "plt.savefig(output_path, dpi=300, format='pdf', bbox_inches='tight', pad_inches=0)\n",
    "plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # scale\n",
    "# images = images / 255\n",
    "# # mean normalize\n",
    "# images = (images - images.mean(dim=(0, 2, 3), keepdim=True)) / images.std(dim=(0, 2, 3), keepdim=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_images = images[:int(0.2*len(images)):]\n",
    "# test_images = images[int(0.2*len(images)):]\n",
    "# train_images.shape, test_images.shape\n",
    "# train_labels = labels[:int(0.2*len(labels))]\n",
    "# test_labels = labels[int(0.2*len(labels)):]\n",
    "# train_labels.shape, test_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = TensorDataset(images, labels)\n",
    "test_loader = DataLoader(test_data, batch_size=512, shuffle=False, num_workers=32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rishabh.mondal/miniconda3/envs/torch_space/lib/python3.11/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import torchvision.models as models\n",
    "\n",
    "efficientnet = models.efficientnet_b0(pretrained=True)\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "efficientnet.classifier[1]=nn.Linear(in_features=1280, out_features=2, bias=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=efficientnet.to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_model = EfficientNetClassifier(\n",
    "    models.efficientnet_b0,EfficientNet_B0_Weights, n_classes=2, activation=nn.ReLU(), dropout=0.1\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for EfficientNet:\n\tMissing key(s) in state_dict: \"classifier.1.weight\", \"classifier.1.bias\". \n\tUnexpected key(s) in state_dict: \"linear.0.weight\", \"linear.0.bias\", \"classifier.0.weight\", \"classifier.0.bias\". ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_state_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/home/rishabh.mondal/Brick-Kilns-project/albk_rishabh/Saved_model/bangladesh_whole_model_no_pretrain.pth\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/torch_space/lib/python3.11/site-packages/torch/nn/modules/module.py:2152\u001b[0m, in \u001b[0;36mModule.load_state_dict\u001b[0;34m(self, state_dict, strict, assign)\u001b[0m\n\u001b[1;32m   2147\u001b[0m         error_msgs\u001b[38;5;241m.\u001b[39minsert(\n\u001b[1;32m   2148\u001b[0m             \u001b[38;5;241m0\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMissing key(s) in state_dict: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m   2149\u001b[0m                 \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m missing_keys)))\n\u001b[1;32m   2151\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(error_msgs) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m-> 2152\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mError(s) in loading state_dict for \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m   2153\u001b[0m                        \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(error_msgs)))\n\u001b[1;32m   2154\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _IncompatibleKeys(missing_keys, unexpected_keys)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for EfficientNet:\n\tMissing key(s) in state_dict: \"classifier.1.weight\", \"classifier.1.bias\". \n\tUnexpected key(s) in state_dict: \"linear.0.weight\", \"linear.0.bias\", \"classifier.0.weight\", \"classifier.0.bias\". "
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(\"/home/rishabh.mondal/Brick-Kilns-project/albk_rishabh/Saved_model/bangladesh_whole_model_no_pretrain.pth\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10025, 3, 224, 224])\n",
      "torch.Size([10025])\n",
      "tensor([0, 0, 0,  ..., 0, 0, 0], dtype=torch.uint8)\n"
     ]
    }
   ],
   "source": [
    "# Load the saved tensors\n",
    "loaded_data1 = torch.load(\"/home/rishabh.mondal/Brick-Kilns-project/albk_rishabh/tensor_data/test_data.pt\")\n",
    "\n",
    "# Access the tensors\n",
    "index1 = loaded_data1['index']\n",
    "images1 = loaded_data1['images']\n",
    "labels1 = loaded_data1['labels']\n",
    "images1 = images1 / 255\n",
    "# mean normalize\n",
    "images1 = (images1 - images1.mean(dim=(0, 2, 3), keepdim=True)) / images1.std(dim=(0, 2, 3), keepdim=True)\n",
    "#print shape of tensors\n",
    "print(images1.shape)\n",
    "print(labels1.shape)\n",
    "#print the labels\n",
    "print(labels1)\n",
    "#count the number of unique labels\n",
    "# count the number of 1s and 0s\n",
    "# unique, counts = np.unique(labels, return_counts=True)\n",
    "# print(dict(zip(unique, counts)))\n",
    "\n",
    "# subset_labels = labels\n",
    "# num_ones = np.count_nonzero(subset_labels == 1)\n",
    "# num_zeros = np.count_nonzero(subset_labels == 0)\n",
    "\n",
    "# print(f\"Number of 1s(train ): {num_ones}\")\n",
    "# print(f\"Number of 0s(train): {num_zeros}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data1 = TensorDataset(images1, labels1)\n",
    "test_loader1 = DataLoader(test_data1, batch_size=512, shuffle=False, num_workers=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:10<00:00,  1.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  tensor(0.9414, device='cuda:0')\n",
      "Precision:  tensor(0.8970, device='cuda:0')\n",
      "Recall:  tensor(0.4933, device='cuda:0')\n",
      "F1:  tensor(0.6365, device='cuda:0')\n",
      "classification report:  {'accuracy': tensor(0.9414, device='cuda:0'), 'precision': tensor(0.8970, device='cuda:0'), 'recall': tensor(0.4933, device='cuda:0'), 'f1': tensor(0.6365, device='cuda:0')}\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    pred_classes =train_model.predict_class(\n",
    "        dataloader=test_loader1, batch_size=254, verbose=True\n",
    "    ).to(device)\n",
    "\n",
    "test_labels = labels1.to(device)\n",
    "print(\"Accuracy: \", accuracy_score(pred_classes,test_labels))\n",
    "print(\"Precision: \", precision_score(pred_classes,test_labels))\n",
    "print(\"Recall: \", recall_score(pred_classes,test_labels))\n",
    "print(\"F1: \", f1_score(pred_classes,test_labels))\n",
    "print(\"classification report: \", classification_report(pred_classes,test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(\"/home/rishabh.mondal/Brick-Kilns-project/albk_rishabh/Saved_model/strafied_efficient_whole_bangladesh.pth\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rishabh.mondal/miniconda3/envs/torch_space/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "    true_labels = []\n",
    "    pred_labels = []\n",
    "    for i, (inputs, labels) in enumerate(test_loader):\n",
    "        inputs = inputs.to('cuda')\n",
    "        labels = labels.to('cuda')\n",
    "        output = model(inputs)\n",
    "        _, preds = torch.max(output, 1)\n",
    "        true_labels.extend(labels.data.cpu().numpy())\n",
    "        pred_labels.extend(preds.data.cpu().numpy())\n",
    "test_accuracy = accuracy_score(true_labels, pred_labels)\n",
    "# test_accuracies.append(test_accuracy)\n",
    "test_precision = precision_score(true_labels, pred_labels)\n",
    "# test_precisions.append(test_precision)\n",
    "test_recall = recall_score(true_labels, pred_labels)\n",
    "# test_recalls.append(test_recall)\n",
    "test_f1 = f1_score(true_labels, pred_labels)\n",
    "# test_f1_scores.append(test_f1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Predicted Positive: 14\n",
      "Total Predicted Negative: 9461\n"
     ]
    }
   ],
   "source": [
    "total_predicted_positive = sum(pred_labels)\n",
    "total_predicted_negative = len(pred_labels) - total_predicted_positive\n",
    "\n",
    "print(\"Total Predicted Positive:\", total_predicted_positive)\n",
    "print(\"Total Predicted Negative:\", total_predicted_negative)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'bool' object has no attribute 'float'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[72], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mclassification_report\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrue_labels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpred_labels\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/ASTRA/astra/torch/metrics.py:43\u001b[0m, in \u001b[0;36mclassification_report\u001b[0;34m(y_pred, y, positive_label)\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mclassification_report\u001b[39m(y_pred, y, positive_label\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m---> 43\u001b[0m     accuracy \u001b[38;5;241m=\u001b[39m \u001b[43maccuracy_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     44\u001b[0m     tp \u001b[38;5;241m=\u001b[39m true_positives_score(y_pred, y, positive_label)\n\u001b[1;32m     45\u001b[0m     fp \u001b[38;5;241m=\u001b[39m false_positives_score(y_pred, y, positive_label)\n",
      "File \u001b[0;32m~/ASTRA/astra/torch/metrics.py:5\u001b[0m, in \u001b[0;36maccuracy_score\u001b[0;34m(y_pred, y)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21maccuracy_score\u001b[39m(y_pred, y):\n\u001b[0;32m----> 5\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m(\u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat\u001b[49m()\u001b[38;5;241m.\u001b[39mmean()\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'bool' object has no attribute 'float'"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "classification_report(true_labels, pred_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'EfficientNet' object has no attribute 'predict_class'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[44], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m----> 2\u001b[0m     pred_classes \u001b[38;5;241m=\u001b[39m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict_class\u001b[49m(\n\u001b[1;32m      3\u001b[0m         dataloader\u001b[38;5;241m=\u001b[39mtest_loader, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m512\u001b[39m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m      4\u001b[0m     )\u001b[38;5;241m.\u001b[39mto(device)\n",
      "File \u001b[0;32m~/miniconda3/envs/torch_space/lib/python3.11/site-packages/torch/nn/modules/module.py:1695\u001b[0m, in \u001b[0;36mModule.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1693\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m modules:\n\u001b[1;32m   1694\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m modules[name]\n\u001b[0;32m-> 1695\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m object has no attribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'EfficientNet' object has no attribute 'predict_class'"
     ]
    }
   ],
   "source": [
    "# with torch.no_grad():\n",
    "#     pred_classes =model.predict_class(\n",
    "#         dataloader=test_loader, batch_size=512, verbose=True\n",
    "#     ).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "sum(): argument 'input' (position 1) must be Tensor, not bool",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[47], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m zero_predictions \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msum\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpred_labels\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m one_predictions \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39msum(pred_labels \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNumber of zero predictions:\u001b[39m\u001b[38;5;124m\"\u001b[39m, zero_predictions\u001b[38;5;241m.\u001b[39mitem())\n",
      "\u001b[0;31mTypeError\u001b[0m: sum(): argument 'input' (position 1) must be Tensor, not bool"
     ]
    }
   ],
   "source": [
    "zero_predictions = torch.sum(pred_labels == 0)\n",
    "one_predictions = torch.sum(pred_labels == 1)\n",
    "\n",
    "print(\"Number of zero predictions:\", zero_predictions.item())\n",
    "print(\"Number of one predictions:\", one_predictions.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "path='/home/rishabh.mondal/Brick-Kilns-project/albk_rishabh/tensor_data_final/test_data.pt'\n",
    "loaded_data1 = torch.load(path)\n",
    "images1 = loaded_data1['images']\n",
    "labels1 = loaded_data1['labels']\n",
    "positive_images = images1[labels1 == 1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "The shape of the mask [4500] at index 0 does not match the shape of the indexed tensor [9475, 3, 224, 224] at index 0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[32], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Filter the images based on the label\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# pred_classes = pred_classes.cpu().numpy()\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m label_1_images \u001b[38;5;241m=\u001b[39m \u001b[43mimages\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlabels1\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(label_1_images\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# Plot the filtered images\u001b[39;00m\n",
      "\u001b[0;31mIndexError\u001b[0m: The shape of the mask [4500] at index 0 does not match the shape of the indexed tensor [9475, 3, 224, 224] at index 0"
     ]
    }
   ],
   "source": [
    "# Filter the images based on the label\n",
    "# pred_classes = pred_classes.cpu().numpy()\n",
    "label_1_images = images[labels1 == 1]\n",
    "print(label_1_images.shape)\n",
    "# Plot the filtered images\n",
    "fig, axes = plt.subplots(5, 5, figsize=(25,25))\n",
    "\n",
    "for i in range(5):\n",
    "    for j in range(5):\n",
    "        # Adjust the index calculation to match the desired grid\n",
    "        index = i * 4 + j\n",
    "        if index < len(label_1_images):\n",
    "            # Transpose the dimensions to (32, 32, 3) for RGB image\n",
    "            image_to_display = label_1_images[index].permute(1, 2, 0)\n",
    "            image_to_display = (image_to_display - image_to_display.min()) / (image_to_display.max() - image_to_display.min())\n",
    "\n",
    "            axes[i, j].imshow(image_to_display)\n",
    "            #put the label\n",
    "            # axes[i, j].set_title(label_1_images[index].item())\n",
    "            axes[i, j].axis('off')\n",
    "        else:\n",
    "            # If there are fewer than 20 images, remove empty subplots\n",
    "            fig.delaxes(axes[i, j])\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_space",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
