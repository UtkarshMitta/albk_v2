{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "import pickle\n",
    "from torch.utils.data import TensorDataset\n",
    "import torch.nn as nn\n",
    "from glob import glob\n",
    "from os.path import expanduser, join, basename, dirname\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from joblib import Parallel, delayed\n",
    "from itertools import product\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from astra.torch.models import ViTClassifier,  ViT_B_16_Weights\n",
    "from astra.torch.utils import train_fn\n",
    "\n",
    "import torchvision.models as models\n",
    "from astra.torch.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "\n",
    "batch_size = 256\n",
    "num_workers = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold:  1\n",
      "trainloader datatype:  torch.uint8\n",
      "testloader datatype:  torch.float32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rishabh.mondal/miniconda3/envs/torch_space/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ViT_B_16_Weights.IMAGENET1K_V1`. You can also use `weights=ViT_B_16_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Loss: 0.00168595: 100%|██████████| 100/100 [4:05:58<00:00, 147.59s/it] \n",
      "100%|██████████| 25/25 [00:14<00:00,  1.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9740\n",
      "Precision: 0.7476\n",
      "Recall: 0.8431\n",
      "F1 Score: 0.7925\n",
      "\n",
      "\n",
      "Fold:  2\n",
      "trainloader datatype:  torch.uint8\n",
      "testloader datatype:  torch.float32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.00403592:  68%|██████▊   | 68/100 [2:41:50<1:30:55, 170.48s/it]"
     ]
    }
   ],
   "source": [
    "\n",
    "# Load the saved fold data from the .pkl file\n",
    "fold_data = torch.load('/home/rishabh.mondal/Brick-Kilns-project/albk_rishabh/cross_val_data/fold_data.pt')\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Lists to store metrics for each fold\n",
    "accuracy_list = []\n",
    "precision_list = []\n",
    "recall_list = []\n",
    "f1_list = []\n",
    "\n",
    "for fold_info in fold_data:\n",
    "    fold = fold_info['fold']\n",
    "    print(\"Fold: \", fold)\n",
    "    X_train = fold_info['X_train']\n",
    "    y_train = fold_info['y_train']\n",
    "    X_test = fold_info['X_test']\n",
    "    y_test = fold_info['y_test']\n",
    "    train_dataset = TensorDataset(X_train, y_train)\n",
    "    test_dataset = TensorDataset(X_test, y_test)\n",
    "\n",
    "    # Create DataLoader for training and testing\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "    # Create and train the model\n",
    "    #print datatype of trainloader\n",
    "    print(\"trainloader datatype: \", train_loader.dataset.tensors[1].dtype)\n",
    "    print(\"testloader datatype: \", test_loader.dataset.tensors[0].dtype)\n",
    "    train_model = ViTClassifier    (\n",
    "        models.vit_b_16, ViT_B_16_Weights, n_classes=2, activation=nn.ReLU(), dropout=0.1\n",
    "    ).to(device)\n",
    "\n",
    "    iter_losses, epoch_losses = train_fn(\n",
    "        train_model,\n",
    "        nn.CrossEntropyLoss(),\n",
    "        dataloader=train_loader,\n",
    "        lr=3e-4,\n",
    "        epochs=100,\n",
    "        verbose=True,\n",
    "        wandb_log=False,\n",
    "    )\n",
    "\n",
    "    # Evaluate the model on the test set\n",
    "    with torch.no_grad():\n",
    "        pred_classes = train_model.predict_class(\n",
    "            dataloader=test_loader, batch_size=batch_size, verbose=True\n",
    "        ).to(device)\n",
    "\n",
    "    test_labels = y_test.to(device)\n",
    "    # Calculate and print metrics for each fold\n",
    "    \n",
    "    accuracy = accuracy_score(test_labels, pred_classes)\n",
    "    precision = precision_score(test_labels, pred_classes)\n",
    "    recall = recall_score(test_labels, pred_classes)\n",
    "    f1 = f1_score(test_labels, pred_classes)\n",
    "\n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    print(f\"Recall: {recall:.4f}\")\n",
    "    print(f\"F1 Score: {f1:.4f}\")\n",
    "    print(\"\\n\")\n",
    "    # Calculate and store metrics for each fold\n",
    "    accuracy_list.append(accuracy_score(test_labels, pred_classes))\n",
    "    precision_list.append(precision_score(test_labels, pred_classes))\n",
    "    recall_list.append(recall_score(test_labels, pred_classes))\n",
    "    f1_list.append(f1_score(test_labels, pred_classes))\n",
    "\n",
    "# Calculate and print the mean of metrics across all folds\n",
    "print(\"Mean Accuracy: \", sum(accuracy_list) / len(accuracy_list))\n",
    "print(\"Mean Precision: \", sum(precision_list) / len(precision_list))\n",
    "print(\"Mean Recall: \", sum(recall_list) / len(recall_list))\n",
    "print(\"Mean F1: \", sum(f1_list) / len(f1_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_space",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
