{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "from os.path import expanduser, join, basename, dirname\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from joblib import Parallel, delayed\n",
    "from shutil import copy\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import torch\n",
    "from tempfile import TemporaryDirectory\n",
    "\n",
    "from albk.data.utils import idx_to_locate\n",
    "use_disjoint_files = False\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from glob import glob\n",
    "from os.path import expanduser, join, basename, dirname\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "from joblib import Parallel, delayed\n",
    "from itertools import product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_common_label_files(path1, path2):\n",
    "    files1 = glob(join(path1, \"*.nc\"))\n",
    "    files2 = glob(join(path2, \"*.nc\"))\n",
    "    \n",
    "    f1_base_files = [basename(f) for f in files1]\n",
    "    f2_base_files = [basename(f) for f in files2]\n",
    "    \n",
    "    common_files = set(f1_base_files).intersection(f2_base_files)\n",
    "    common_label_files = []\n",
    "    for file in common_files:\n",
    "        ds1 = xr.open_dataset(join(path1, file))\n",
    "        ds2 = xr.open_dataset(join(path2, file))\n",
    "        if np.all(ds1.label.values == ds2.label.values):\n",
    "            common_label_files.append(file)\n",
    "    \n",
    "    return list(map(lambda f: join(path1, f), common_label_files))\n",
    "\n",
    "def get_disjoint_files(path1, path2):\n",
    "    files1 = glob(join(path1, \"*.nc\"))\n",
    "    files2 = glob(join(path2, \"*.nc\"))\n",
    "    \n",
    "    f1_base_files = [basename(f) for f in files1]\n",
    "    f2_base_files = [basename(f) for f in files2]\n",
    "    \n",
    "    disjoint_files = set(f1_base_files).symmetric_difference(f2_base_files)\n",
    "    \n",
    "    f1_disjoint = [f for f in disjoint_files if f in f1_base_files]\n",
    "    f1_disjoint = list(map(lambda f: join(path1, f), f1_disjoint))\n",
    "\n",
    "    f2_disjoint = [f for f in disjoint_files if f in f2_base_files]\n",
    "    f2_disjoint = list(map(lambda f: join(path2, f), f2_disjoint))\n",
    "    \n",
    "    return f1_disjoint + f2_disjoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moderator rishabh\n",
      "      Moderator files 151\n",
      "      Common label files 98\n",
      "      Disjoint files 0\n",
      "      Total files from rishabh and ('shataxi', 'suraj') 249\n",
      "      Total annotatated files 249\n",
      "Moderator suraj\n",
      "      Moderator files 88\n",
      "      Common label files 64\n",
      "      Disjoint files 0\n",
      "      Total files from suraj and ('rishabh', 'vannsh') 152\n",
      "      Total annotatated files 401\n",
      "Total dataset size 10025\n",
      "All Brick Kilns 1042\n",
      "All Non-brick Kilns 8983\n"
     ]
    }
   ],
   "source": [
    "base_path = expanduser(\"~/bangladesh_labels/bkdb/india_labels/region/delhi/sarath_data\")\n",
    "paths = {\"rishabh\": (\"shataxi\", \"suraj\"), \"suraj\": (\"rishabh\", \"vannsh\")}\n",
    "\n",
    "all_labeled_files = []\n",
    "for moderator, annotators in paths.items():\n",
    "    # Get moderator files\n",
    "    moderator_path = join(base_path, \"moderated\", moderator)\n",
    "    moderator_files = glob(join(moderator_path, \"*.nc\"))\n",
    "    \n",
    "    # Get annotator common label files\n",
    "    annotator1_path = join(base_path, annotators[0])\n",
    "    annotator2_path = join(base_path, annotators[1])\n",
    "    \n",
    "    common_base_files = get_common_label_files(annotator1_path, annotator2_path)\n",
    "    \n",
    "    # Get disjoint files\n",
    "    disjoint_files = get_disjoint_files(annotator1_path, annotator2_path)\n",
    "    \n",
    "    all_files = moderator_files + common_base_files\n",
    "    if use_disjoint_files:\n",
    "        all_files.extend(disjoint_files)\n",
    "    assert len(all_files) == len(set(all_files))\n",
    "    all_labeled_files.extend(all_files)\n",
    "    \n",
    "    print(\"Moderator\", moderator)\n",
    "    print(\" \"*5, \"Moderator files\", len(moderator_files))\n",
    "    print(\" \"*5, \"Common label files\", len(common_base_files))\n",
    "    print(\" \"*5, \"Disjoint files\", len(disjoint_files))\n",
    "    print(\" \"*5, f\"Total files from {moderator} and {annotators}\", len(all_files))\n",
    "    print(\" \"*5, \"Total annotatated files\", len(all_labeled_files))\n",
    "    \n",
    "print(\"Total dataset size\", len(all_labeled_files) * 25)\n",
    "def get_bk_stats(path):\n",
    "    ds = xr.open_dataset(path)\n",
    "    z = (ds.label.values == \"Z\").sum()\n",
    "    f = (ds.label.values == \"F\").sum()\n",
    "    o = (ds.label.values == \"O\").sum()\n",
    "    return {\"Z\": z, \"F\": f, \"O\": o}\n",
    "\n",
    "df = pd.DataFrame([get_bk_stats(path) for path in all_labeled_files])\n",
    "\n",
    "df_sum = df.sum(axis=0)\n",
    "\n",
    "print(\"All Brick Kilns\", df_sum[\"Z\"] + df_sum[\"F\"])\n",
    "print(\"All Non-brick Kilns\", df_sum[\"O\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/home/rishabh.mondal/bangladesh_labels/bkdb/india_labels/region/delhi/sarath_data/moderated/rishabh/28.90,77.25.nc', '/home/rishabh.mondal/bangladesh_labels/bkdb/india_labels/region/delhi/sarath_data/moderated/rishabh/28.80,77.45.nc', '/home/rishabh.mondal/bangladesh_labels/bkdb/india_labels/region/delhi/sarath_data/moderated/rishabh/28.77,77.60.nc', '/home/rishabh.mondal/bangladesh_labels/bkdb/india_labels/region/delhi/sarath_data/moderated/rishabh/28.86,77.17.nc', '/home/rishabh.mondal/bangladesh_labels/bkdb/india_labels/region/delhi/sarath_data/moderated/rishabh/28.84,77.53.nc']\n"
     ]
    }
   ],
   "source": [
    "print(all_labeled_files[:5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "401\n"
     ]
    }
   ],
   "source": [
    "images_path = expanduser(\"~/bkdb/statewise/sarath_data1/\")\n",
    "# load_path = \"/home/rishabh.mondal/Brick-Kilns-project/albk_rishabh/temporary\"\n",
    "files = all_labeled_files\n",
    "# print(files)\n",
    "print(len(files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 401/401 [00:07<00:00, 56.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<U17 torch.uint8 torch.uint8\n",
      "torch.uint8\n",
      "(10025,) torch.Size([10025, 3, 224, 224]) torch.Size([10025])\n"
     ]
    }
   ],
   "source": [
    "def get_index_and_image(file):\n",
    "    index = []\n",
    "    images = []\n",
    "    labels = []\n",
    "    base_name = basename(file)\n",
    "    # print(base_name)\n",
    "    image_path = join(images_path, base_name).replace(\".nc\", \".zarr\")\n",
    "    # print(image_path)\n",
    "    label_ds = xr.open_dataset(file)\n",
    "    # print (label_ds)\n",
    "    image_ds = xr.open_zarr(image_path, consolidated=False)\n",
    "    # image = image_ds.data.reshape(-1, 224, 224, 3)\n",
    "    for lat_lag, lon_lag in product(range(-2, 3), repeat=2):\n",
    "        index.append(base_name.replace(\".nc\", \"\")+f\"_{lat_lag}_{lon_lag}\")\n",
    "        images.append(torch.tensor(image_ds.sel(lat_lag=lat_lag, lon_lag=lon_lag)['data'].values)[np.newaxis, ...])\n",
    "        labels.append(torch.tensor((label_ds.sel(lat_lag=lat_lag, lon_lag=lon_lag)['label'].values != \"O\").astype(np.uint8)))\n",
    "        \n",
    "    return index, images, labels\n",
    "\n",
    "\n",
    "\n",
    "def get_data():\n",
    "    out = Parallel(n_jobs=32)(delayed(get_index_and_image)(file) for file in tqdm(files, total=len(files)))\n",
    "    index = np.concatenate([np.array(idx) for idx, _, _ in out])\n",
    "    images = torch.concat([torch.einsum(\"nhwc->nchw\", torch.concat(imgs)) for _, imgs, _ in out])\n",
    "    # scale\n",
    "    # images = images / 255\n",
    "    # mean normalize\n",
    "    # images = (images - images.mean(dim=(0, 2, 3), keepdim=True)) / images.std(dim=(0, 2, 3), keepdim=True)\n",
    "    \n",
    "    labels = np.concatenate([np.array(lbl) for _, _, lbl in out])\n",
    "    labels = torch.tensor(labels, dtype=torch.uint8)\n",
    "    #check the all dytpes\n",
    "    print(index.dtype, images.dtype, labels.dtype)\n",
    "    return index, images, labels\n",
    "\n",
    "index, images, labels = get_data()\n",
    "print(images.dtype)\n",
    "print(index.shape, images.shape, labels.shape)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.uint8\n",
      "torch.uint8\n"
     ]
    }
   ],
   "source": [
    "print(images.dtype)\n",
    "print(labels.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### test data path# save_path=\"/home/rishabh.mondal/Brick-Kilns-project/albk_rishabh/tensor_data/test_data.pt\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.uint8\n"
     ]
    }
   ],
   "source": [
    "# save the tensors data \n",
    "# print(images.dtype)\n",
    "# save_path=\"/home/rishabh.mondal/Brick-Kilns-project/albk_rishabh/tensor_data/test_data.pt\"\n",
    "# torch.save({\n",
    "#     'index': index,\n",
    "#     'images': images,\n",
    "#     'labels': labels\n",
    "# }, save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_space",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
