{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "from os.path import expanduser, join, basename, dirname\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from joblib import Parallel, delayed\n",
    "from shutil import copy\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import torch\n",
    "from tempfile import TemporaryDirectory\n",
    "\n",
    "from albk.data.utils import idx_to_locate\n",
    "use_disjoint_files = False\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from glob import glob\n",
    "from os.path import expanduser, join, basename, dirname\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "from joblib import Parallel, delayed\n",
    "from itertools import product\n",
    "from astra.torch.models import EfficientNetClassifier,EfficientNet_B0_Weights   \n",
    "from astra.torch.utils import train_fn\n",
    "\n",
    "import torchvision.models as models\n",
    "from astra.torch.metrics import accuracy_score, f1_score, precision_score, recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the saved tensors\n",
    "loaded_data = torch.load(\"/home/rishabh.mondal/Brick-Kilns-project/albk_rishabh/tensor_data/data.pt\")\n",
    "\n",
    "# Access the tensors\n",
    "index = loaded_data['index']\n",
    "images = loaded_data['images']\n",
    "labels = loaded_data['labels']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.transforms as transforms\n",
    "\n",
    "images=images[:2000]\n",
    "labels=labels[:2000]\n",
    "images = images / 255\n",
    "    # mean normalize\n",
    "images = (images - images.mean(dim=(0, 2, 3), keepdim=True)) / images.std(dim=(0, 2, 3), keepdim=True)\n",
    "images.shape, labels.shape\n",
    "aug = transforms.Compose([\n",
    "    transforms.Resize(224),\n",
    "    transforms.RandomResizedCrop(224,scale=(0.2,1.0)),\n",
    "    transforms.RandomGrayscale(p=0.2),\n",
    "    transforms.ColorJitter(0.4, 0.4, 0.4, 0.4),\n",
    "    transforms.GaussianBlur(kernel_size=23, sigma=(0.1, 2.0)),\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.RandomVerticalFlip(p=0.5),\n",
    "    transforms.RandomRotation(degrees=50),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std=[0.229, 0.224, 0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rishabh.mondal/miniconda3/envs/torch_space/lib/python3.11/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "images = aug(images)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({0: 1369, 1: 131})\n",
      "Counter({0: 457, 1: 43})\n",
      "Fold 1 - Train: Counter({0: 1369, 1: 131}), Test: Counter({0: 457, 1: 43})\n",
      "Counter({0: 1369, 1: 131})\n",
      "Counter({0: 457, 1: 43})\n",
      "Fold 2 - Train: Counter({0: 1369, 1: 131}), Test: Counter({0: 457, 1: 43})\n",
      "Counter({0: 1370, 1: 130})\n",
      "Counter({0: 456, 1: 44})\n",
      "Fold 3 - Train: Counter({0: 1370, 1: 130}), Test: Counter({0: 456, 1: 44})\n",
      "Counter({0: 1370, 1: 130})\n",
      "Counter({0: 456, 1: 44})\n",
      "Fold 4 - Train: Counter({0: 1370, 1: 130}), Test: Counter({0: 456, 1: 44})\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "fold_data = []  # List to store data from each fold\n",
    "\n",
    "seed = 42  # Use your desired random seed\n",
    "splitter = StratifiedKFold(n_splits=4, shuffle=True, random_state=seed)\n",
    "images = images / 255\n",
    "    # mean normalize\n",
    "images = (images - images.mean(dim=(0, 2, 3), keepdim=True)) / images.std(dim=(0, 2, 3), keepdim=True)\n",
    "for fold, (train_idx, test_idx) in enumerate(splitter.split(images, labels)):\n",
    "    X_train, X_test = images[train_idx], images[test_idx]\n",
    "    y_train, y_test = labels[train_idx], labels[test_idx]\n",
    "\n",
    "    # Count occurrences of each class in train and test sets\n",
    "    train_counter = Counter(y_train.numpy())\n",
    "    test_counter = Counter(y_test.numpy())\n",
    "    print(train_counter)\n",
    "    print(test_counter)\n",
    "    print(f\"Fold {fold + 1} - Train: {train_counter}, Test: {test_counter}\")\n",
    "\n",
    "    fold_data.append({\n",
    "        'fold': fold + 1,\n",
    "        'X_train': X_train,\n",
    "        'X_test': X_test,\n",
    "        'y_train': y_train,\n",
    "        'y_test': y_test,\n",
    "        'train_counter': train_counter,\n",
    "        'test_counter': test_counter\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold:  1\n",
      "trainloader datatype:  torch.uint8\n",
      "testloader datatype:  torch.float32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rishabh.mondal/miniconda3/envs/torch_space/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=EfficientNet_B0_Weights.IMAGENET1K_V1`. You can also use `weights=EfficientNet_B0_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Loss: 0.00018147: 100%|██████████| 100/100 [03:55<00:00,  2.36s/it]\n",
      "100%|██████████| 1/1 [00:00<00:00,  4.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9440\n",
      "Precision: 0.7778\n",
      "Recall: 0.4884\n",
      "F1 Score: 0.6000\n",
      "\n",
      "\n",
      "Fold:  2\n",
      "trainloader datatype:  torch.uint8\n",
      "testloader datatype:  torch.float32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.00088380: 100%|██████████| 100/100 [03:33<00:00,  2.14s/it]\n",
      "100%|██████████| 1/1 [00:00<00:00,  6.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9460\n",
      "Precision: 0.7667\n",
      "Recall: 0.5349\n",
      "F1 Score: 0.6301\n",
      "\n",
      "\n",
      "Fold:  3\n",
      "trainloader datatype:  torch.uint8\n",
      "testloader datatype:  torch.float32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.00172171: 100%|██████████| 100/100 [04:31<00:00,  2.71s/it]\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9420\n",
      "Precision: 0.7586\n",
      "Recall: 0.5000\n",
      "F1 Score: 0.6027\n",
      "\n",
      "\n",
      "Fold:  4\n",
      "trainloader datatype:  torch.uint8\n",
      "testloader datatype:  torch.float32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.00771242: 100%|██████████| 100/100 [05:28<00:00,  3.28s/it]\n",
      "100%|██████████| 1/1 [00:00<00:00,  5.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9360\n",
      "Precision: 0.7727\n",
      "Recall: 0.3864\n",
      "F1 Score: 0.5152\n",
      "\n",
      "\n",
      "Mean Accuracy:  tensor(0.9420, device='cuda:0')\n",
      "Mean Precision:  tensor(0.7689, device='cuda:0')\n",
      "Mean Recall:  tensor(0.4774, device='cuda:0')\n",
      "Mean F1:  tensor(0.5870, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "batch_size=512\n",
    "# Lists to store metrics for each fold\n",
    "accuracy_list = []\n",
    "precision_list = []\n",
    "recall_list = []\n",
    "f1_list = []\n",
    "\n",
    "for fold_info in fold_data:\n",
    "    fold = fold_info['fold']\n",
    "    print(\"Fold: \", fold)\n",
    "    X_train = fold_info['X_train']\n",
    "    y_train = fold_info['y_train']\n",
    "    X_test = fold_info['X_test']\n",
    "    y_test = fold_info['y_test']\n",
    "    train_dataset = TensorDataset(X_train, y_train)\n",
    "    test_dataset = TensorDataset(X_test, y_test)\n",
    "\n",
    "    # Create DataLoader for training and testing\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "    # Create and train the model\n",
    "    #print datatype of trainloader\n",
    "    print(\"trainloader datatype: \", train_loader.dataset.tensors[1].dtype)\n",
    "    print(\"testloader datatype: \", test_loader.dataset.tensors[0].dtype)\n",
    "    train_model = EfficientNetClassifier    (\n",
    "        models.efficientnet_b0, EfficientNet_B0_Weights, n_classes=2, activation=nn.ReLU(), dropout=0.1\n",
    "    ).to(device)\n",
    "\n",
    "    iter_losses, epoch_losses = train_fn(\n",
    "        train_model,\n",
    "        nn.CrossEntropyLoss(),\n",
    "        dataloader=train_loader,\n",
    "        lr=3e-4,\n",
    "        epochs=100,\n",
    "        verbose=True,\n",
    "        wandb_log=False,\n",
    "    )\n",
    "\n",
    "    # Evaluate the model on the test set\n",
    "    with torch.no_grad():\n",
    "        pred_classes = train_model.predict_class(\n",
    "            dataloader=test_loader, batch_size=batch_size, verbose=True\n",
    "        ).to(device)\n",
    "\n",
    "    test_labels = y_test.to(device)\n",
    "    # Calculate and print metrics for each fold\n",
    "    \n",
    "    accuracy = accuracy_score(pred_classes,test_labels)\n",
    "    precision = precision_score( pred_classes,test_labels)\n",
    "    recall = recall_score( pred_classes,test_labels)\n",
    "    f1 = f1_score( pred_classes,test_labels)\n",
    "\n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    print(f\"Recall: {recall:.4f}\")\n",
    "    print(f\"F1 Score: {f1:.4f}\")\n",
    "    print(\"\\n\")\n",
    "    # Calculate and store metrics for each fold\n",
    "    accuracy_list.append(accuracy_score( pred_classes,test_labels))\n",
    "    precision_list.append(precision_score( pred_classes,test_labels))\n",
    "    recall_list.append(recall_score( pred_classes,test_labels))\n",
    "    f1_list.append(f1_score( pred_classes,test_labels))\n",
    "\n",
    "# Calculate and print the mean of metrics across all folds\n",
    "print(\"Mean Accuracy: \", sum(accuracy_list) / len(accuracy_list))\n",
    "print(\"Mean Precision: \", sum(precision_list) / len(precision_list))\n",
    "print(\"Mean Recall: \", sum(recall_list) / len(recall_list))\n",
    "print(\"Mean F1: \", sum(f1_list) / len(f1_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the saved tensors\n",
    "loaded_data = torch.load(\"/home/rishabh.mondal/Brick-Kilns-project/albk_rishabh/tensor_data/test_data.pt\")\n",
    "\n",
    "# Access the tensors\n",
    "index1 = loaded_data['index']\n",
    "images1 = loaded_data['images']\n",
    "labels1= loaded_data['labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rishabh.mondal/miniconda3/envs/torch_space/lib/python3.11/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "images1=images1[:2000]\n",
    "labels1=labels1[:2000]\n",
    "images1.shape, labels1.shape\n",
    "images1 = images1 / 255\n",
    "    # mean normalize\n",
    "images1 = (images1 - images1.mean(dim=(0, 2, 3), keepdim=True)) / images1.std(dim=(0, 2, 3), keepdim=True)\n",
    "images1=aug(images1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({0: 1308, 1: 192})\n",
      "Counter({0: 437, 1: 63})\n",
      "Fold 1 - Train: Counter({0: 1308, 1: 192}), Test: Counter({0: 437, 1: 63})\n",
      "Counter({0: 1309, 1: 191})\n",
      "Counter({0: 436, 1: 64})\n",
      "Fold 2 - Train: Counter({0: 1309, 1: 191}), Test: Counter({0: 436, 1: 64})\n",
      "Counter({0: 1309, 1: 191})\n",
      "Counter({0: 436, 1: 64})\n",
      "Fold 3 - Train: Counter({0: 1309, 1: 191}), Test: Counter({0: 436, 1: 64})\n",
      "Counter({0: 1309, 1: 191})\n",
      "Counter({0: 436, 1: 64})\n",
      "Fold 4 - Train: Counter({0: 1309, 1: 191}), Test: Counter({0: 436, 1: 64})\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "fold_data1 = []  # List to store data from each fold\n",
    "\n",
    "seed = 42  # Use your desired random seed\n",
    "splitter = StratifiedKFold(n_splits=4, shuffle=True, random_state=seed)\n",
    "# images1 = images1 / 255\n",
    "#     # mean normalize\n",
    "# images1 = (images1 - images1.mean(dim=(0, 2, 3), keepdim=True)) / images1.std(dim=(0, 2, 3), keepdim=True)\n",
    "for fold, (train_idx, test_idx) in enumerate(splitter.split(images1, labels1)):\n",
    "    X_train, X_test = images1[train_idx], images1[test_idx]\n",
    "    y_train, y_test = labels1[train_idx], labels1[test_idx]\n",
    "\n",
    "    # Count occurrences of each class in train and test sets\n",
    "    train_counter = Counter(y_train.numpy())\n",
    "    test_counter = Counter(y_test.numpy())\n",
    "    print(train_counter)\n",
    "    print(test_counter)\n",
    "    print(f\"Fold {fold + 1} - Train: {train_counter}, Test: {test_counter}\")\n",
    "\n",
    "    fold_data1.append({\n",
    "        'fold': fold + 1,\n",
    "        'X_train': X_train,\n",
    "        'X_test': X_test,\n",
    "        'y_train': y_train,\n",
    "        'y_test': y_test,\n",
    "        'train_counter': train_counter,\n",
    "        'test_counter': test_counter\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rishabh.mondal/miniconda3/envs/torch_space/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=EfficientNet_B0_Weights.IMAGENET1K_V1`. You can also use `weights=EfficientNet_B0_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold:  1\n",
      "trainloader datatype:  torch.uint8\n",
      "testloader datatype:  torch.float32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.00283062: 100%|██████████| 100/100 [05:38<00:00,  3.39s/it]\n",
      "100%|██████████| 1/1 [00:00<00:00,  6.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8800\n",
      "Precision: 0.5517\n",
      "Recall: 0.2540\n",
      "F1 Score: 0.3478\n",
      "\n",
      "\n",
      "Fold:  2\n",
      "trainloader datatype:  torch.uint8\n",
      "testloader datatype:  torch.float32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.00087110: 100%|██████████| 100/100 [05:06<00:00,  3.06s/it]\n",
      "100%|██████████| 1/1 [00:00<00:00,  7.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8920\n",
      "Precision: 0.6923\n",
      "Recall: 0.2812\n",
      "F1 Score: 0.4000\n",
      "\n",
      "\n",
      "Fold:  3\n",
      "trainloader datatype:  torch.uint8\n",
      "testloader datatype:  torch.float32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.00034782: 100%|██████████| 100/100 [05:38<00:00,  3.38s/it]\n",
      "100%|██████████| 1/1 [00:00<00:00,  7.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8940\n",
      "Precision: 0.7895\n",
      "Recall: 0.2344\n",
      "F1 Score: 0.3614\n",
      "\n",
      "\n",
      "Fold:  4\n",
      "trainloader datatype:  torch.uint8\n",
      "testloader datatype:  torch.float32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.00173927: 100%|██████████| 100/100 [05:24<00:00,  3.24s/it]\n",
      "100%|██████████| 1/1 [00:00<00:00,  7.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8740\n",
      "Precision: 0.5128\n",
      "Recall: 0.3125\n",
      "F1 Score: 0.3883\n",
      "\n",
      "\n",
      "Mean Accuracy:  tensor(0.8850, device='cuda:0')\n",
      "Mean Precision:  tensor(0.6366, device='cuda:0')\n",
      "Mean Recall:  tensor(0.2705, device='cuda:0')\n",
      "Mean F1:  tensor(0.3744, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "batch_size=512\n",
    "# Lists to store metrics for each fold\n",
    "accuracy_list = []\n",
    "precision_list = []\n",
    "recall_list = []\n",
    "f1_list = []\n",
    "\n",
    "for fold_info in fold_data1:\n",
    "    fold = fold_info['fold']\n",
    "    print(\"Fold: \", fold)\n",
    "    X_train = fold_info['X_train']\n",
    "    y_train = fold_info['y_train']\n",
    "    X_test = fold_info['X_test']\n",
    "    y_test = fold_info['y_test']\n",
    "    train_dataset = TensorDataset(X_train, y_train)\n",
    "    test_dataset = TensorDataset(X_test, y_test)\n",
    "\n",
    "    # Create DataLoader for training and testing\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "    # Create and train the model\n",
    "    #print datatype of trainloader\n",
    "    print(\"trainloader datatype: \", train_loader.dataset.tensors[1].dtype)\n",
    "    print(\"testloader datatype: \", test_loader.dataset.tensors[0].dtype)\n",
    "    train_model = EfficientNetClassifier    (\n",
    "        models.efficientnet_b0, EfficientNet_B0_Weights, n_classes=2, activation=nn.ReLU(), dropout=0.1\n",
    "    ).to(device)\n",
    "\n",
    "    iter_losses, epoch_losses = train_fn(\n",
    "        train_model,\n",
    "        nn.CrossEntropyLoss(),\n",
    "        dataloader=train_loader,\n",
    "        lr=3e-4,\n",
    "        epochs=100,\n",
    "        verbose=True,\n",
    "        wandb_log=False,\n",
    "    )\n",
    "\n",
    "    # Evaluate the model on the test set\n",
    "    with torch.no_grad():\n",
    "        pred_classes = train_model.predict_class(\n",
    "            dataloader=test_loader, batch_size=batch_size, verbose=True\n",
    "        ).to(device)\n",
    "\n",
    "    test_labels = y_test.to(device)\n",
    "    # Calculate and print metrics for each fold\n",
    "    \n",
    "    accuracy = accuracy_score(pred_classes,test_labels)\n",
    "    precision = precision_score( pred_classes,test_labels)\n",
    "    recall = recall_score( pred_classes,test_labels)\n",
    "    f1 = f1_score( pred_classes,test_labels)\n",
    "\n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    print(f\"Recall: {recall:.4f}\")\n",
    "    print(f\"F1 Score: {f1:.4f}\")\n",
    "    print(\"\\n\")\n",
    "    # Calculate and store metrics for each fold\n",
    "    accuracy_list.append(accuracy_score( pred_classes,test_labels))\n",
    "    precision_list.append(precision_score( pred_classes,test_labels))\n",
    "    recall_list.append(recall_score( pred_classes,test_labels))\n",
    "    f1_list.append(f1_score( pred_classes,test_labels))\n",
    "\n",
    "# Calculate and print the mean of metrics across all folds\n",
    "print(\"Mean Accuracy: \", sum(accuracy_list) / len(accuracy_list))\n",
    "print(\"Mean Precision: \", sum(precision_list) / len(precision_list))\n",
    "print(\"Mean Recall: \", sum(recall_list) / len(recall_list))\n",
    "print(\"Mean F1: \", sum(f1_list) / len(f1_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2000, 3, 224, 224]) torch.Size([2000])\n",
      "torch.Size([2000, 3, 224, 224]) torch.Size([2000])\n"
     ]
    }
   ],
   "source": [
    "print(images.shape, labels.shape)\n",
    "print(images1.shape, labels1.shape)  \n",
    "images = images / 255\n",
    "    # mean normalize\n",
    "images = (images - images.mean(dim=(0, 2, 3), keepdim=True)) / images.std(dim=(0, 2, 3), keepdim=True)\n",
    "images1 = images1 / 255\n",
    "    # mean normalize\n",
    "images1 = (images1 - images1.mean(dim=(0, 2, 3), keepdim=True)) / images1.std(dim=(0, 2, 3), keepdim=True)\n",
    "train_dataset = TensorDataset(images, labels)\n",
    "train_loader = DataLoader(train_dataset, batch_size=512, shuffle=True, num_workers=8)\n",
    "test_dataset = TensorDataset(images1, labels1)\n",
    "test_loaderr = DataLoader(test_dataset, batch_size=512, shuffle=False, num_workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.00016192: 100%|██████████| 100/100 [10:45<00:00,  6.45s/it]\n"
     ]
    }
   ],
   "source": [
    "train_model = EfficientNetClassifier(\n",
    "    models.efficientnet_b0,EfficientNet_B0_Weights, n_classes=2, activation=nn.ReLU(), dropout=0.1\n",
    ").to(device)\n",
    "\n",
    "iter_losses, epoch_losses = train_fn(\n",
    "    train_model,\n",
    "    nn.CrossEntropyLoss(),\n",
    "    dataloader=train_loader,\n",
    "    lr=3e-4,\n",
    "    epochs=100,\n",
    "    verbose=True,\n",
    "    wandb_log=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000\n",
      "2000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:04<00:00,  1.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000\n",
      "Accuracy:  tensor(0.8695, device='cuda:0')\n",
      "Precision:  tensor(0., device='cuda:0')\n",
      "Recall:  tensor(0., device='cuda:0')\n",
      "F1:  tensor(0., device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "print(len(labels1))\n",
    "print(len(images1))\n",
    "test_dataset = TensorDataset(images1, labels1)\n",
    "test_loader = DataLoader(test_dataset, batch_size=512, shuffle=False, num_workers=8)\n",
    "with torch.no_grad():\n",
    "    pred_classes =train_model.predict_class(\n",
    "        dataloader=test_loader, batch_size=254, verbose=True\n",
    "    ).to(device)\n",
    "print(len(pred_classes))\n",
    "test_labels = labels1.to(device)\n",
    "print(\"Accuracy: \", accuracy_score(pred_classes,test_labels))\n",
    "print(\"Precision: \", precision_score(pred_classes,test_labels))\n",
    "print(\"Recall: \", recall_score(pred_classes,test_labels))\n",
    "print(\"F1: \", f1_score(pred_classes,test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_space",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
